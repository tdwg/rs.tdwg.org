{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to build Markdown pages that provide term metadata for simple vocabularies\n",
    "# Steve Baskauf 2020-06-28 CC0\n",
    "# This script merges static Markdown header and footer documents with term information tables (in Markdown) generated from data in the rs.tdwg.org repo from the TDWG Github site\n",
    "\n",
    "# Note: this script calls a function from http_library.py, which requires importing the requests, csv, and json modules\n",
    "import re\n",
    "import requests   # best library to manage HTTP transactions\n",
    "import csv        # library to read/write/parse CSV files\n",
    "import json       # library to convert JSON to Python data structures\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------\n",
    "# Configuration section\n",
    "# -----------------\n",
    "\n",
    "# !!!! Note !!!!\n",
    "# This is an example of a simple vocabulary without categories. For a complex example\n",
    "# with multiple namespaces and several categories, see build-page-categories.ipynb\n",
    "\n",
    "# This is the base URL for raw files from the branch of the repo that has been pushed to GitHub. In this example,\n",
    "# the branch is named \"pathway\"\n",
    "githubBaseUri = 'https://raw.githubusercontent.com/tdwg/rs.tdwg.org/createchrono/'\n",
    "\n",
    "headerFileName = 'termlist-header.md'\n",
    "footerFileName = 'termlist-footer.md'\n",
    "outFileName = 'chrono.md'\n",
    "\n",
    "# This is a Python list of the database names of the term lists to be included in the document.\n",
    "termLists = ['chronometricage']\n",
    "\n",
    "# NOTE! There may be problems unless every term list is of the same vocabulary type since the number of columns will differ\n",
    "# However, there probably aren't any circumstances where mixed types will be used to generate the same page.\n",
    "vocab_type = 1 # 1 is simple vocabulary, 2 is simple controlled vocabulary, 3 is c.v. with broader hierarchy\n",
    "\n",
    "# Terms in large vocabularies like Darwin and Audubon Cores may be organized into categories using tdwgutility_organizedInClass\n",
    "# If so, those categories can be used to group terms in the generated term list document.\n",
    "organized_in_categories = False\n",
    "\n",
    "# If organized in categories, the display_order list must contain the IRIs that are values of tdwgutility_organizedInClass\n",
    "# If not organized into categories, the value is irrelevant. There just needs to be one item in the list.\n",
    "display_order = ['']\n",
    "display_label = ['Vocabulary'] # these are the section labels for the categories in the page\n",
    "display_comments = [''] # these are the comments about the category to be appended following the section labels\n",
    "display_id = ['Vocabulary'] # these are the fragment identifiers for the associated sections for the categories\n",
    "\n",
    "# ---------------\n",
    "# Function definitions\n",
    "# ---------------\n",
    "\n",
    "# replace URL with link\n",
    "#\n",
    "def createLinks(text):\n",
    "    def repl(match):\n",
    "        if match.group(1)[-1] == '.':\n",
    "            return '<a href=\"' + match.group(1)[:-1] + '\">' + match.group(1)[:-1] + '</a>.'\n",
    "        return '<a href=\"' + match.group(1) + '\">' + match.group(1) + '</a>'\n",
    "\n",
    "    pattern = '(https?://[^\\s,;\\)\"]*)'\n",
    "    result = re.sub(pattern, repl, text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f948e1660fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mterm_lists_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithubBaseUri\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'term-lists/term-lists.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtermList\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtermLists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mterm_list_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'list_iri'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtermList\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "term_lists_info = []\n",
    "\n",
    "frame = pd.read_csv(githubBaseUri + 'term-lists/term-lists.csv', na_filter=False)\n",
    "for termList in termLists:\n",
    "    term_list_dict = {'list_iri': termList}\n",
    "    term_list_dict = {'database': termList}\n",
    "    for index,row in frame.iterrows():\n",
    "        if row['database'] == termList:\n",
    "            term_list_dict['pref_ns_prefix'] = row['vann_preferredNamespacePrefix']\n",
    "            term_list_dict['pref_ns_uri'] = row['vann_preferredNamespaceUri']\n",
    "            term_list_dict['list_iri'] = row['list']\n",
    "    term_lists_info.append(term_list_dict)\n",
    "print(term_lists_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "column_list = ['pref_ns_prefix', 'pref_ns_uri', 'term_localName', 'label', 'rdfs_comment', 'dcterms_description', 'examples', 'term_modified', 'term_deprecated', 'rdf_type', 'replaces_term', 'replaces1_term']\n",
    "if vocab_type == 2:\n",
    "    column_list += ['controlled_value_string']\n",
    "elif vocab_type == 3:\n",
    "    column_list += ['controlled_value_string', 'skos_broader']\n",
    "if organized_in_categories:\n",
    "    column_list.append('tdwgutility_organizedInClass')\n",
    "column_list.append('version_iri')\n",
    "\n",
    "# Create list of lists metadata table\n",
    "table_list = []\n",
    "for term_list in term_lists_info:\n",
    "    # retrieve versions metadata for term list\n",
    "    versions_url = githubBaseUri + term_list['database'] + '-versions/' + term_list['database'] + '-versions.csv'\n",
    "    versions_df = pd.read_csv(versions_url, na_filter=False)\n",
    "    \n",
    "    # retrieve current term metadata for term list\n",
    "    data_url = githubBaseUri + term_list['database'] + '/' + term_list['database'] + '.csv'\n",
    "    frame = pd.read_csv(data_url, na_filter=False)\n",
    "    for index,row in frame.iterrows():\n",
    "        row_list = [term_list['pref_ns_prefix'], term_list['pref_ns_uri'], row['term_localName'], row['label'], row['rdfs_comment'], row['dcterms_description'], row['examples'], row['term_modified'], row['term_deprecated'], row['rdf_type'], row['replaces_term'], row['replaces1_term']]\n",
    "        if vocab_type == 2:\n",
    "            row_list += [row['controlled_value_string']]\n",
    "        elif vocab_type == 3:\n",
    "            if row['skos_broader'] =='':\n",
    "                row_list += [row['controlled_value_string'], '']\n",
    "            else:\n",
    "                row_list += [row['controlled_value_string'], term_list['pref_ns_prefix'] + ':' + row['skos_broader']]\n",
    "        if organized_in_categories:\n",
    "            row_list.append(row['tdwgutility_organizedInClass'])\n",
    "\n",
    "        # Borrowed terms really don't have implemented versions. They may be lacking values for version_status.\n",
    "        # In their case, their version IRI will be omitted.\n",
    "        found = False\n",
    "        for vindex, vrow in versions_df.iterrows():\n",
    "            if vrow['term_localName']==row['term_localName'] and vrow['version_status']=='recommended':\n",
    "                found = True\n",
    "                version_iri = vrow['version']\n",
    "                # NOTE: the current hack for non-TDWG terms without a version is to append # to the end of the term IRI\n",
    "                if version_iri[len(version_iri)-1] == '#':\n",
    "                    version_iri = ''\n",
    "        if not found:\n",
    "            version_iri = ''\n",
    "        row_list.append(version_iri)\n",
    "\n",
    "        table_list.append(row_list)\n",
    "\n",
    "# Turn list of lists into dataframe\n",
    "terms_df = pd.DataFrame(table_list, columns = column_list)\n",
    "\n",
    "terms_sorted_by_label = terms_df.sort_values(by='label')\n",
    "terms_sorted_by_localname = terms_df.sort_values(by='term_localName')\n",
    "terms_sorted_by_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate an index sorted alphabetically by lowercase term local name. Omit this index if the terms have opaque local names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the index of terms grouped by category and sorted alphabetically by lowercase term local name\n",
    "\n",
    "text = '### 3.1 Index By Term Name\\n\\n'\n",
    "text += '(See also [3.2 Index By Label](#32-index-by-label))\\n\\n'\n",
    "for category in range(0,len(display_order)):\n",
    "    text += '**' + display_label[category] + '**\\n'\n",
    "    text += '\\n'\n",
    "    if organized_in_categories:\n",
    "        filtered_table = terms_sorted_by_localname[terms_sorted_by_localname['tdwgutility_organizedInClass']==display_order[category]]\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        filtered_table = terms_sorted_by_localname\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    for row_index,row in filtered_table.iterrows():\n",
    "        curie = row['pref_ns_prefix'] + \":\" + row['term_localName']\n",
    "        curie_anchor = curie.replace(':','_')\n",
    "            text += '[' + curie + '](#' + curie_anchor + ') |\\n'\n",
    "    text = text[:len(text)-2] # remove final trailing vertical bar and newline\n",
    "    text += '\\n\\n' # put back removed newline\n",
    "index_by_name = text\n",
    "\n",
    "print(index_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate an index by term label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n\\n'\n",
    "\n",
    "# Comment out the following two lines if there is no index by local names\n",
    "#text = '### 3.2 Index By Label\\n\\n'\n",
    "#text += '(See also [3.1 Index By Term Name](#31-index-by-term-name))\\n\\n'\n",
    "for category in range(0,len(display_order)):\n",
    "    if organized_in_categories:\n",
    "        text += '**' + display_label[category] + '**\\n'\n",
    "        text += '\\n'\n",
    "        filtered_table = terms_sorted_by_label[terms_sorted_by_label['tdwgutility_organizedInClass']==display_order[category]]\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        filtered_table = terms_sorted_by_label\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    for row_index,row in filtered_table.iterrows():\n",
    "        if row_index == 0 or (row_index != 0 and row['label'] != filtered_table.iloc[row_index - 1].loc['label']): # this is a hack to prevent duplicate labels\n",
    "            curie_anchor = row['pref_ns_prefix'] + \"_\" + row['term_localName']\n",
    "                text += '[' + row['label'] + '](#' + curie_anchor + ') |\\n'\n",
    "    text = text[:len(text)-2] # remove final trailing vertical bar and newline\n",
    "    text += '\\n\\n' # put back removed newline\n",
    "\n",
    "index_by_label = text\n",
    "\n",
    "print(index_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_df = pd.read_csv('https://raw.githubusercontent.com/tdwg/rs.tdwg.org/master/decisions/decisions-links.csv', na_filter=False)\n",
    "\n",
    "# generate a table for each term, with terms grouped by category\n",
    "\n",
    "# generate the Markdown for the terms table\n",
    "text = '## 4 Vocabulary\\n'\n",
    "for category in range(0,len(display_order)):\n",
    "    if organized_in_categories:\n",
    "        text += '### 4.' + str(category + 1) + ' ' + display_label[category] + '\\n'\n",
    "        text += '\\n'\n",
    "        text += display_comments[category] # insert the comments for the category, if any.\n",
    "        filtered_table = terms_sorted_by_localname[terms_sorted_by_localname['tdwgutility_organizedInClass']==display_order[category]]\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        filtered_table = terms_sorted_by_localname\n",
    "        filtered_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for row_index,row in filtered_table.iterrows():\n",
    "        text += '<table>\\n'\n",
    "        curie = row['pref_ns_prefix'] + \":\" + row['term_localName']\n",
    "        curieAnchor = curie.replace(':','_')\n",
    "        text += '\\t<thead>\\n'\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<th colspan=\"2\"><a id=\"' + curieAnchor + '\"></a>Term Name  ' + curie + '</th>\\n'\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "        text += '\\t</thead>\\n'\n",
    "        text += '\\t<tbody>\\n'\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<td>Term IRI</td>\\n'\n",
    "        uri = row['pref_ns_uri'] + row['term_localName']\n",
    "        text += '\\t\\t\\t<td><a href=\"' + uri + '\">' + uri + '</a></td>\\n'\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<td>Modified</td>\\n'\n",
    "        text += '\\t\\t\\t<td>' + row['term_modified'] + '</td>\\n'\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if row['version_iri'] != '':\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td>Term version IRI</td>\\n'\n",
    "            text += '\\t\\t\\t<td><a href=\"' + row['version_iri'] + '\">' + row['version_iri'] + '</a></td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<td>Label</td>\\n'\n",
    "        text += '\\t\\t\\t<td>' + row['label'] + '</td>\\n'\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if row['term_deprecated'] != '':\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td></td>\\n'\n",
    "            text += '\\t\\t\\t<td><strong>This term is deprecated and should no longer be used.</strong></td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<td>Definition</td>\\n'\n",
    "        text += '\\t\\t\\t<td>' + row['definition'] + '</td>\\n'\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if row['dcterms_description'] != '':\n",
    "        #if row['notes'] != '':\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td>Notes</td>\\n'\n",
    "            text += '\\t\\t\\t<td>' + createLinks(row['dcterms_description']) + '</td>\\n'\n",
    "            #text += '\\t\\t\\t<td>' + createLinks(row['notes']) + '</td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if row['examples'] != '':\n",
    "        #if row['usage'] != '':\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td>Examples</td>\\n'\n",
    "            text += '\\t\\t\\t<td>' + createLinks(row['examples']) + '</td>\\n'\n",
    "            #text += '\\t\\t\\t<td>' + createLinks(row['usage']) + '</td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if (vocab_type == 2 or vocab_type == 3) and row['controlled_value_string'] != '': # controlled vocabulary\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td>Controlled value</td>\\n'\n",
    "            text += '\\t\\t\\t<td>' + row['controlled_value_string'] + '</td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        if vocab_type == 3 and row['skos_broader'] != '': # controlled vocabulary with skos:broader relationships\n",
    "            text += '\\t\\t<tr>\\n'\n",
    "            text += '\\t\\t\\t<td>Has broader concept</td>\\n'\n",
    "            curieAnchor = row['skos_broader'].replace(':','_')\n",
    "            text += '\\t\\t\\t<td><a href=\"#' + curieAnchor + '\">' + row['skos_broader'] + '</a></td>\\n'\n",
    "            text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        text += '\\t\\t<tr>\\n'\n",
    "        text += '\\t\\t\\t<td>Type</td>\\n'\n",
    "        if row['type'] == 'http://www.w3.org/1999/02/22-rdf-syntax-ns#Property':\n",
    "            text += '\\t\\t\\t<td>Property</td>\\n'\n",
    "        elif row['type'] == 'http://www.w3.org/2000/01/rdf-schema#Class':\n",
    "            text += '\\t\\t\\t<td>Class</td>\\n'\n",
    "        elif row['type'] == 'http://www.w3.org/2004/02/skos/core#Concept':\n",
    "            text += '\\t\\t\\t<td>Concept</td>\\n'\n",
    "        else:\n",
    "            text += '\\t\\t\\t<td>' + row['type'] + '</td>\\n' # this should rarely happen\n",
    "        text += '\\t\\t</tr>\\n'\n",
    "\n",
    "        # Look up decisions related to this term\n",
    "        for drow_index,drow in decisions_df.iterrows():\n",
    "            if drow['linked_affected_resource'] == uri:\n",
    "                text += '\\t\\t<tr>\\n'\n",
    "                text += '\\t\\t\\t<td>Executive Committee decision</td>\\n'\n",
    "                text += '\\t\\t\\t<td><a href=\"http://rs.tdwg.org/decisions/' + drow['decision_localName'] + '\">http://rs.tdwg.org/decisions/' + drow['decision_localName'] + '</a></td>\\n'\n",
    "                text += '\\t\\t</tr>\\n'                        \n",
    "\n",
    "        text += '\\t</tbody>\\n'\n",
    "        text += '</table>\\n'\n",
    "        text += '\\n'\n",
    "    text += '\\n'\n",
    "term_table = text\n",
    "\n",
    "print(term_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify to display the indices that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = index_by_label + term_table\n",
    "#text = index_by_name + index_by_label + term_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in header and footer, merge with terms table, and output\n",
    "\n",
    "headerObject = open(headerFileName, 'rt', encoding='utf-8')\n",
    "header = headerObject.read()\n",
    "headerObject.close()\n",
    "\n",
    "footerObject = open(footerFileName, 'rt', encoding='utf-8')\n",
    "footer = footerObject.read()\n",
    "footerObject.close()\n",
    "\n",
    "output = header + text + footer\n",
    "outputObject = open(outFileName, 'wt', encoding='utf-8')\n",
    "outputObject.write(output)\n",
    "outputObject.close()\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
